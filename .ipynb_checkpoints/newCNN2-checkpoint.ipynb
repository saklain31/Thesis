{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = ['/home/saklain/rad/balc.txt','/home/saklain/rad/door.txt','/home/saklain/rad/midroom.txt']\n",
    "#with open('/home/saklain/rad/traindata.txt', 'w') as outfile:\n",
    " #   for fname in filenames:\n",
    "  #      with open(fname) as infile:\n",
    "   #         outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.839827 18.593677  4.169149 ... 15.006199 22.493886 13.255091]\n",
      " [ 9.494929 20.803282  4.310922 ... 14.930078 23.816222 13.355334]\n",
      " [10.365546 21.642272  4.634742 ... 15.748691 24.289007 13.776883]\n",
      " ...\n",
      " [20.554249 18.57388  11.797091 ... 23.251001 20.868045 17.95352 ]\n",
      " [17.060326 15.42661   7.872376 ... 21.590985 20.233291 17.240152]\n",
      " [19.688239 17.789868  9.669624 ... 22.972672 21.340896 18.129271]]\n",
      "3600000\n",
      "<class 'numpy.ndarray'>\n",
      "Their indices are  (array([    80,     80,     80, ..., 221081, 221081, 221081]), array([ 1,  2,  4, ...,  8, 10, 11]))\n"
     ]
    }
   ],
   "source": [
    "#TRAINING DATA\n",
    "import numpy as np\n",
    "file = open(\"/home/saklain/rad/traindata.txt\", \"r\") \n",
    "t=0\n",
    "mainlist=[]\n",
    "mylist = []\n",
    "k=-156.535598\n",
    "cnt=0\n",
    "for line in file:\n",
    "    if(cnt==0):\n",
    "        line=float(line.replace(\"\\n\",\"\"))\n",
    "        mylist.append(line)\n",
    "    if(cnt==1):\n",
    "        line=float(line.replace(\"\\n\",\"\"))\n",
    "        mylist.append(line)\n",
    "    if(cnt==3):\n",
    "        line=float(line.replace(\"\\n\",\"\"))\n",
    "        mylist.append(line)\n",
    "    \n",
    "    t=t+1\n",
    "    cnt=cnt+1\n",
    "    if cnt==7:\n",
    "        cnt=0\n",
    "    if(t%28==0):\n",
    "        t=0\n",
    "        a=np.asarray(mylist)\n",
    "        mainlist.append(a)\n",
    "        #print(a)\n",
    "        mylist.clear()\n",
    "        #print(\"*******\")\n",
    "        \n",
    "data=np.asarray(mainlist)\n",
    "print(data)\n",
    "print(data.size)\n",
    "print(type(data))\n",
    "#data=np.delete(data, 3048, 0)\n",
    "#data=np.delete(data, 3568, 0)\n",
    "print(\"Their indices are \", np.nonzero(data == -156.535598))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000.0\n",
      "<class 'numpy.ndarray'>\n",
      "test1 err  2051\n"
     ]
    }
   ],
   "source": [
    "print(data.size/12)\n",
    "print(type(data))\n",
    "#data=np.delete(data, 3048, 0)\n",
    "#data=np.delete(data, 3568, 0)\n",
    "print(\"test1 err \", np.unique(np.nonzero(data == -156.535598)[0]).size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "15000.0\n",
      "85000.0\n",
      "15000.0\n",
      "85000.0\n",
      "15000.0\n",
      "85000.0\n"
     ]
    }
   ],
   "source": [
    "print(data.size/12)\n",
    "sp = np.split(data, 3)\n",
    "data1= sp[0]\n",
    "data2= sp[1]\n",
    "data3= sp[2]\n",
    "\n",
    "print(data1.size/12)\n",
    "#print(data1)\n",
    "print(data2.size/12)\n",
    "#print(data2)\n",
    "print(data3.size/12)\n",
    "\n",
    "test1 = data1[85000:100000]\n",
    "print(test1.size/12)\n",
    "train1 = data1[0:85000]\n",
    "print(train1.size/12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test2 = data2[85000:100000]\n",
    "print(test2.size/12)\n",
    "train2 = data2[0:85000]\n",
    "print(train2.size/12)\n",
    "\n",
    "test3 = data3[85000:100000]\n",
    "print(test3.size/12)\n",
    "train3 = data3[0:85000]\n",
    "print(train3.size/12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 err  143\n",
      "train1 err  1221\n",
      "test2 err  10\n",
      "train2 err  479\n",
      "test3 err  0\n",
      "train3 err  198\n",
      "test1 err  14857\n",
      "train1 err  83779\n",
      "test2 err  14990\n",
      "train2 err  84521\n",
      "test3 err  15000\n",
      "train3 err  84802\n"
     ]
    }
   ],
   "source": [
    "print(\"test1 err \", np.unique(np.nonzero(test1 == -156.535598)[0]).size)\n",
    "print(\"train1 err \", np.unique(np.nonzero(train1 == -156.535598)[0]).size)\n",
    "print(\"test2 err \", np.unique(np.nonzero(test2 == -156.535598)[0]).size)\n",
    "print(\"train2 err \", np.unique(np.nonzero(train2 == -156.535598)[0]).size)\n",
    "print(\"test3 err \", np.unique(np.nonzero(test3 == -156.535598)[0]).size)\n",
    "print(\"train3 err \", np.unique(np.nonzero(train3 == -156.535598)[0]).size)\n",
    "\n",
    "print(\"test1 err \", 15000-np.unique(np.nonzero(test1 == -156.535598)[0]).size)\n",
    "print(\"train1 err \", 85000-np.unique(np.nonzero(train1 == -156.535598)[0]).size)\n",
    "print(\"test2 err \", 15000-np.unique(np.nonzero(test2 == -156.535598)[0]).size)\n",
    "print(\"train2 err \", 85000-np.unique(np.nonzero(train2 == -156.535598)[0]).size)\n",
    "print(\"test3 err \", 15000-np.unique(np.nonzero(test3 == -156.535598)[0]).size)\n",
    "print(\"train3 err \", 85000-np.unique(np.nonzero(train3 == -156.535598)[0]).size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n"
     ]
    }
   ],
   "source": [
    "while np.nonzero(train1 == -156.535598):\n",
    "    arr = np.nonzero(train1 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    train1=np.delete(train1, np.unique(arr[0])[0], 0)\n",
    "    \n",
    "\n",
    "    \n",
    "while np.nonzero(train2 == -156.535598):\n",
    "    arr = np.nonzero(train2 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    train2=np.delete(train2, np.unique(arr[0])[0], 0)\n",
    "    \n",
    "    \n",
    "while np.nonzero(train3 == -156.535598):\n",
    "    arr = np.nonzero(train3 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    train3=np.delete(train3, np.unique(arr[0])[0], 0)\n",
    "    \n",
    "while np.nonzero(test1 == -156.535598):\n",
    "    arr = np.nonzero(test1 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    test1=np.delete(test1, np.unique(arr[0])[0], 0)\n",
    "\n",
    "while np.nonzero(test2 == -156.535598):\n",
    "    arr = np.nonzero(test2 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    test2=np.delete(test2, np.unique(arr[0])[0], 0)\n",
    "\n",
    "while np.nonzero(test3 == -156.535598):\n",
    "    arr = np.nonzero(test3 == -156.535598)\n",
    "    #print(np.unique(arr[0]).size)\n",
    "    if np.unique(arr[0]).size==0:\n",
    "        print(\"zero\")\n",
    "        break\n",
    "    test3=np.delete(test3, np.unique(arr[0])[0], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14857.0\n",
      "83779.0\n",
      "14990.0\n",
      "84521.0\n",
      "15000.0\n",
      "84802.0\n",
      "253102.0\n",
      "44847.0\n",
      "297949.0\n",
      "267949.0\n"
     ]
    }
   ],
   "source": [
    "a=test1.size/12\n",
    "print(a)\n",
    "b=train1.size/12\n",
    "print(b)\n",
    "\n",
    "c=test2.size/12\n",
    "print(c)\n",
    "d=train2.size/12\n",
    "print(d)\n",
    "\n",
    "e=test3.size/12\n",
    "print(e)\n",
    "f=train3.size/12\n",
    "print(f)\n",
    "\n",
    "trainset = np.append(train1,train2,axis=0)\n",
    "trainset = np.append(trainset,train3,axis=0)\n",
    "\n",
    "testset = np.append(test1,test2,axis=0)\n",
    "testset = np.append(testset,test3,axis=0)\n",
    "\n",
    "dataset = np.append(trainset,testset,axis=0)\n",
    "\n",
    "\n",
    "print(trainset.size/12)\n",
    "print(testset.size/12)\n",
    "print(dataset.size/12)\n",
    "\n",
    "dataset = dataset[30000:297949]\n",
    "print(dataset.size/12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "253102\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp = []\n",
    "out = []\n",
    "\n",
    "for i in range(int(b)):\n",
    "    temp.append(0)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "    \n",
    "for i in range(int(d)):\n",
    "    temp.append(1)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "    \n",
    "for i in range(int(f)):\n",
    "    temp.append(2)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "    \n",
    "        \n",
    "labels=np.asarray(out)\n",
    "print(labels)\n",
    "print(labels.size)\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "44847\n",
      "<class 'numpy.ndarray'>\n",
      "297949\n",
      "267949\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp = []\n",
    "out = []\n",
    "\n",
    "for i in range(int(a)):\n",
    "    temp.append(0)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "    \n",
    "for i in range(int(c)):\n",
    "    temp.append(1)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "    \n",
    "for i in range(int(e)):\n",
    "    temp.append(2)\n",
    "    tempfin=np.asarray(temp)\n",
    "    out.append(tempfin)\n",
    "    temp.clear()\n",
    "\n",
    "\n",
    "labels_test=np.asarray(out)\n",
    "print(labels_test)\n",
    "print(labels_test.size)\n",
    "print(type(labels_test))\n",
    "\n",
    "total_labels = np.append(labels,labels_test,axis=0)\n",
    "print(total_labels.size)\n",
    "total_labels = total_labels[30000:297949]\n",
    "print(total_labels.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************SET***************::::::: 1\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.3991 - acc: 0.8179 - val_loss: 0.8657 - val_acc: 0.7926\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 7s 28us/step - loss: 0.2475 - acc: 0.9092 - val_loss: 0.3127 - val_acc: 0.8840\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 7s 28us/step - loss: 0.2332 - acc: 0.9147 - val_loss: 0.4679 - val_acc: 0.8718\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.2231 - acc: 0.9186 - val_loss: 0.2104 - val_acc: 0.9313\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 7s 28us/step - loss: 0.2138 - acc: 0.9225 - val_loss: 0.6967 - val_acc: 0.7539\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.2059 - acc: 0.9250 - val_loss: 0.7787 - val_acc: 0.6457\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.1993 - acc: 0.9281 - val_loss: 0.8825 - val_acc: 0.6129\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.1918 - acc: 0.9305 - val_loss: 0.9048 - val_acc: 0.6613\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 7s 29us/step - loss: 0.1835 - acc: 0.9342 - val_loss: 0.8612 - val_acc: 0.6902\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 7s 30us/step - loss: 0.1781 - acc: 0.9359 - val_loss: 1.0619 - val_acc: 0.5777\n",
      "**************SET***************::::::: 2\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2081 - acc: 0.9265 - val_loss: 0.1439 - val_acc: 0.9685\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 16s 66us/step - loss: 0.2016 - acc: 0.9294 - val_loss: 0.2284 - val_acc: 0.9355\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 11s 46us/step - loss: 0.2004 - acc: 0.9298 - val_loss: 0.2929 - val_acc: 0.9390\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 7s 31us/step - loss: 0.1998 - acc: 0.9304 - val_loss: 0.7585 - val_acc: 0.7898\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 8s 31us/step - loss: 0.2009 - acc: 0.9297 - val_loss: 0.3543 - val_acc: 0.9395\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 7s 30us/step - loss: 0.2024 - acc: 0.9299 - val_loss: 0.1658 - val_acc: 0.9656\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 7s 31us/step - loss: 0.2026 - acc: 0.9300 - val_loss: 0.3924 - val_acc: 0.9335\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.2044 - acc: 0.9295 - val_loss: 0.4186 - val_acc: 0.9210\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2031 - acc: 0.9302 - val_loss: 0.4859 - val_acc: 0.9021\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.2040 - acc: 0.9302 - val_loss: 0.2535 - val_acc: 0.9454\n",
      "**************SET***************::::::: 3\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.1131 - acc: 0.9665 - val_loss: 3.8283 - val_acc: 0.1792\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.1124 - acc: 0.9673 - val_loss: 3.0199 - val_acc: 0.1557\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.1123 - acc: 0.9673 - val_loss: 1.9987 - val_acc: 0.1769\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.1122 - acc: 0.9676 - val_loss: 2.9496 - val_acc: 0.1630\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.1124 - acc: 0.9682 - val_loss: 3.7620 - val_acc: 0.1517\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.1157 - acc: 0.9678 - val_loss: 4.9073 - val_acc: 0.1247\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.1155 - acc: 0.9676 - val_loss: 3.4815 - val_acc: 0.1584\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.1150 - acc: 0.9683 - val_loss: 3.9067 - val_acc: 0.1669\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 8s 31us/step - loss: 0.1150 - acc: 0.9682 - val_loss: 4.3555 - val_acc: 0.1398\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.1171 - acc: 0.9684 - val_loss: 2.8542 - val_acc: 0.1497\n",
      "**************SET***************::::::: 4\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2257 - acc: 0.9254 - val_loss: 0.6566 - val_acc: 0.8290\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2149 - acc: 0.9298 - val_loss: 1.1087 - val_acc: 0.6344\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2083 - acc: 0.9331 - val_loss: 0.7104 - val_acc: 0.7724\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2068 - acc: 0.9339 - val_loss: 0.8694 - val_acc: 0.6034\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 9s 39us/step - loss: 0.2035 - acc: 0.9349 - val_loss: 1.5088 - val_acc: 0.5865\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2020 - acc: 0.9353 - val_loss: 0.6627 - val_acc: 0.6967\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 9s 35us/step - loss: 0.2010 - acc: 0.9364 - val_loss: 0.4469 - val_acc: 0.8096\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2016 - acc: 0.9361 - val_loss: 1.0080 - val_acc: 0.6511\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2014 - acc: 0.9363 - val_loss: 1.2203 - val_acc: 0.5877\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2024 - acc: 0.9364 - val_loss: 1.0725 - val_acc: 0.6099\n",
      "**************SET***************::::::: 5\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2435 - acc: 0.9207 - val_loss: 0.0261 - val_acc: 0.9913\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 9s 39us/step - loss: 0.2390 - acc: 0.9225 - val_loss: 0.0170 - val_acc: 0.9953\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2368 - acc: 0.9238 - val_loss: 0.0224 - val_acc: 0.9968\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.2368 - acc: 0.9235 - val_loss: 0.0356 - val_acc: 0.9919\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 8s 32us/step - loss: 0.2398 - acc: 0.9233 - val_loss: 0.0503 - val_acc: 0.9814\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2522 - acc: 0.9241 - val_loss: 0.0203 - val_acc: 0.9927\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 9s 39us/step - loss: 0.2507 - acc: 0.9245 - val_loss: 0.0282 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2521 - acc: 0.9253 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2484 - acc: 0.9258 - val_loss: 0.0404 - val_acc: 0.9839\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2473 - acc: 0.9261 - val_loss: 0.0293 - val_acc: 0.9906\n",
      "**************SET***************::::::: 6\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2217 - acc: 0.9339 - val_loss: 0.2786 - val_acc: 0.9487\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.2174 - acc: 0.9347 - val_loss: 0.3791 - val_acc: 0.8836\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2109 - acc: 0.9350 - val_loss: 0.7307 - val_acc: 0.7313\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2084 - acc: 0.9364 - val_loss: 0.2344 - val_acc: 0.9390\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2117 - acc: 0.9353 - val_loss: 0.4853 - val_acc: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2189 - acc: 0.9363 - val_loss: 0.6322 - val_acc: 0.8375\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.2189 - acc: 0.9360 - val_loss: 0.3018 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2130 - acc: 0.9337 - val_loss: 0.5151 - val_acc: 0.8522\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2090 - acc: 0.9359 - val_loss: 1.0801 - val_acc: 0.6319\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 10s 41us/step - loss: 0.2089 - acc: 0.9354 - val_loss: 0.8431 - val_acc: 0.7074\n",
      "**************SET***************::::::: 7\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 10s 40us/step - loss: 0.2039 - acc: 0.9375 - val_loss: 0.7143 - val_acc: 0.8103\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 9s 39us/step - loss: 0.2049 - acc: 0.9372 - val_loss: 0.7145 - val_acc: 0.7283\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 9s 36us/step - loss: 0.2023 - acc: 0.9382 - val_loss: 0.8110 - val_acc: 0.8282\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2001 - acc: 0.9392 - val_loss: 0.5231 - val_acc: 0.8690\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.1990 - acc: 0.9400 - val_loss: 0.7464 - val_acc: 0.7610\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.1965 - acc: 0.9405 - val_loss: 0.8014 - val_acc: 0.8374\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.1951 - acc: 0.9412 - val_loss: 0.7695 - val_acc: 0.7912\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.1941 - acc: 0.9415 - val_loss: 0.3574 - val_acc: 0.9252\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.1946 - acc: 0.9408 - val_loss: 0.3926 - val_acc: 0.9132\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.1934 - acc: 0.9422 - val_loss: 0.8124 - val_acc: 0.8403\n",
      "**************SET***************::::::: 8\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2286 - acc: 0.9322 - val_loss: 0.0669 - val_acc: 0.9795\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2279 - acc: 0.9322 - val_loss: 0.0668 - val_acc: 0.9738\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 9s 38us/step - loss: 0.2260 - acc: 0.9326 - val_loss: 0.3203 - val_acc: 0.8977\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 9s 39us/step - loss: 0.2276 - acc: 0.9319 - val_loss: 0.0916 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2268 - acc: 0.9318 - val_loss: 0.0252 - val_acc: 0.9989\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2269 - acc: 0.9318 - val_loss: 0.3563 - val_acc: 0.8512\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 8s 34us/step - loss: 0.2280 - acc: 0.9311 - val_loss: 0.2706 - val_acc: 0.8809\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2272 - acc: 0.9318 - val_loss: 0.0553 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2254 - acc: 0.9329 - val_loss: 0.1027 - val_acc: 0.9909\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2267 - acc: 0.9323 - val_loss: 0.1756 - val_acc: 0.9470\n",
      "**************SET***************::::::: 9\n",
      "Train on 241154 samples, validate on 26795 samples\n",
      "Epoch 1/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2203 - acc: 0.9337 - val_loss: 0.2300 - val_acc: 0.9618\n",
      "Epoch 2/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2171 - acc: 0.9357 - val_loss: 0.4647 - val_acc: 0.8037\n",
      "Epoch 3/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2325 - acc: 0.9347 - val_loss: 0.1314 - val_acc: 0.9686\n",
      "Epoch 4/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2373 - acc: 0.9356 - val_loss: 0.1515 - val_acc: 0.9678\n",
      "Epoch 5/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2449 - acc: 0.9354 - val_loss: 0.2585 - val_acc: 0.9179\n",
      "Epoch 6/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2364 - acc: 0.9372 - val_loss: 0.2325 - val_acc: 0.9497\n",
      "Epoch 7/10\n",
      "241154/241154 [==============================] - 8s 35us/step - loss: 0.2396 - acc: 0.9367 - val_loss: 0.1110 - val_acc: 0.9744\n",
      "Epoch 8/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2424 - acc: 0.9379 - val_loss: 0.4980 - val_acc: 0.8512\n",
      "Epoch 9/10\n",
      "241154/241154 [==============================] - 8s 33us/step - loss: 0.2475 - acc: 0.9374 - val_loss: 0.1180 - val_acc: 0.9727\n",
      "Epoch 10/10\n",
      "241154/241154 [==============================] - 9s 37us/step - loss: 0.2350 - acc: 0.9384 - val_loss: 0.1348 - val_acc: 0.9717\n",
      "**************SET***************::::::: 10\n",
      "Train on 241155 samples, validate on 26794 samples\n",
      "Epoch 1/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2469 - acc: 0.9340 - val_loss: 0.0766 - val_acc: 0.9900\n",
      "Epoch 2/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2377 - acc: 0.9345 - val_loss: 0.0527 - val_acc: 0.9953\n",
      "Epoch 3/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2428 - acc: 0.9344 - val_loss: 0.0355 - val_acc: 0.9965\n",
      "Epoch 4/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2405 - acc: 0.9343 - val_loss: 0.0408 - val_acc: 0.9944\n",
      "Epoch 5/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2414 - acc: 0.9343 - val_loss: 0.0507 - val_acc: 0.9925\n",
      "Epoch 6/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2399 - acc: 0.9349 - val_loss: 0.0457 - val_acc: 0.9939\n",
      "Epoch 7/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2437 - acc: 0.9346 - val_loss: 0.0672 - val_acc: 0.9951\n",
      "Epoch 8/10\n",
      "241155/241155 [==============================] - 8s 33us/step - loss: 0.2628 - acc: 0.9338 - val_loss: 0.0746 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      "241155/241155 [==============================] - 8s 35us/step - loss: 0.2610 - acc: 0.9348 - val_loss: 0.1867 - val_acc: 0.9474\n",
      "Epoch 10/10\n",
      "241155/241155 [==============================] - 8s 34us/step - loss: 0.2591 - acc: 0.9341 - val_loss: 0.0493 - val_acc: 0.9935\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=12))\n",
    "model.add(Dense(48, activation='softmax'))\n",
    "\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#print(trainset.size/12)\n",
    "#print(labels.size)\n",
    "#print(testset.size/12)\n",
    "#print(labels_test.size)\n",
    "\n",
    "from sklearn.model_selection import KFold  \n",
    "\n",
    "kf=KFold(n_splits=10)\n",
    "\n",
    "cnt=0\n",
    "for train,test in kf.split(dataset):\n",
    "    cnt=cnt+1\n",
    "    print(\"**************SET***************:::::::\",cnt)\n",
    "    xtrain,xtest = dataset[train],dataset[test]\n",
    "    ytrain,ytest = total_labels[train],total_labels[test]\n",
    "\n",
    "    # Convert labels to categorical one-hot encoding\n",
    "    one_hot_labels = keras.utils.to_categorical(ytrain, num_classes=3)\n",
    "    one_hot_labels_test = keras.utils.to_categorical(ytest, num_classes=3)\n",
    "\n",
    "    # Train the model, iterating on the data in batches of 32 samples\n",
    "    model.fit(xtrain, one_hot_labels, epochs=10,validation_data=(xtest, one_hot_labels_test), batch_size=32)\n",
    "    #model.save('/home/saklain/ThesisCNN/newmodel2.h5')\n",
    "\n",
    "     #score = model.evaluate(data_test,one_hot_labels_test, batch_size=32)\n",
    "    #print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6] [0 1 2]\n",
      "[0 1 2 5 6] [3 4]\n",
      "[0 1 2 3 4] [5 6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#kf=KFold(n_splits=3)\n",
    "#data = np.array([[1,2],[12,1],[1,4],[1,7],[4,1],[4,6],[1,8]])\n",
    "#for train,test in kf.split(data):\n",
    " #   print(train,test)\n",
    "  #  xtrain,xtest = data[train],data[test]\n",
    "    #ytrain,ytest = total_labels[train],total_labels[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(testset,one_hot_labels_test, batch_size=32)\n",
    "#print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
